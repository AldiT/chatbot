{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh, thanks !  i'm fine. this is an evening in my timezone\n",
      "ðŸ˜„ here is afternoon ! \n"
     ]
    }
   ],
   "source": [
    "data_path_human = \"../data/rDany/human_text.txt\"\n",
    "data_path_robot = \"../data/rDany/robot_text.txt\"\n",
    "\n",
    "with open(data_path_human, \"r\") as f:\n",
    "    human_lines = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(data_path_robot, \"r\") as f:\n",
    "    robot_lines = f.read().split(\"\\n\")\n",
    "print(human_lines[1])\n",
    "print(robot_lines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "sentence_size = 258\n",
    "\n",
    "text_vectorization_layer = TextVectorization(max_tokens=vocabulary_size, output_sequence_length=sentence_size)\n",
    "text_vectorization_layer.adapt(human_lines + robot_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193514it [00:27, 44070.25it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/glove.twitter.27B.50d.txt\", \"r\") as f:\n",
    "    dict_w2v = {}\n",
    "    problems = []\n",
    "    \n",
    "    for line in tqdm(f):\n",
    "        \n",
    "        tokens = line.split()\n",
    "        \n",
    "        word = tokens[0]\n",
    "        vector = np.array(tokens[1:], dtype=np.float32)\n",
    "        \n",
    "        if vector.shape[0] == 50:\n",
    "            dict_w2v[word] = vector\n",
    "        else:\n",
    "            problems.append({word: vector})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5485/5485 [00:09<00:00, 565.85it/s]\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(text_vectorization_layer.get_vocabulary())\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for token in tqdm(text_vectorization_layer.get_vocabulary()):\n",
    "    \n",
    "    embedding = dict_w2v.get(token)\n",
    "    if embedding is not None:\n",
    "        embedding_matrix[text_vectorization_layer([token]).numpy()[0, 0]] = embedding\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.10279983e-02,  4.86490011e-01, -1.83469996e-01,  3.30749989e-01,\n",
       "       -4.70070004e-01, -6.94120005e-02,  1.13100004e+00,  3.17909986e-01,\n",
       "       -1.24720000e-01,  8.28909993e-01, -3.50919992e-01,  5.10840006e-02,\n",
       "       -6.40070009e+00, -8.04430008e-01, -8.51570010e-01,  2.32920006e-01,\n",
       "       -8.70200023e-02, -4.23040003e-01, -2.67019987e-01, -3.67500004e-03,\n",
       "        4.65970010e-01,  1.35539994e-01,  1.04249999e-01,  9.52400029e-01,\n",
       "       -4.85289991e-02,  2.45450005e-01,  3.84009987e-01,  2.28350004e-03,\n",
       "        1.19099998e+00, -3.03739995e-01, -4.44409996e-01,  8.26079994e-02,\n",
       "        2.38509998e-01,  3.32679987e-01,  1.32699996e-01,  3.87419999e-01,\n",
       "        5.44470012e-01,  2.11710006e-01, -8.30610022e-02,  2.97399998e-01,\n",
       "       -1.08580005e+00, -3.62289995e-01,  4.38259989e-01,  3.00089985e-01,\n",
       "       -7.43770003e-02, -3.87529999e-01, -2.26109996e-01,  7.15169981e-02,\n",
       "        1.34729996e-01, -7.37999976e-02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(text_vectorization_layer)\n",
    "model.add(tf.keras.layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=True))\n",
    "model.add(tf.keras.layers.LSTM(128))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['cat is there on the window']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[-2.4095742e-20, -8.4734786e-20,  9.8878463e-20, -8.4335270e-20,\n",
       "        -8.8498031e-20,  1.1737989e-19,  2.4859112e-21, -3.1846722e-19,\n",
       "         1.6712448e-19, -2.2653656e-20]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\"cat is there on the window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
