{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_human = \"../data/human_text.txt\"\n",
    "data_path_robot = \"../data/robot_text.txt\"\n",
    "\n",
    "with open(data_path_human, \"r\") as f:\n",
    "    human_lines = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(data_path_robot, \"r\") as f:\n",
    "    robot_lines = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in human_lines]\n",
    "human_lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in human_lines]\n",
    "robot_lines = [re.sub(r\"\\[\\w+\\]\",'',line) for line in robot_lines]\n",
    "robot_lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in robot_lines]\n",
    "# grouping lines by response pair\n",
    "pairs = list(zip(human_lines,robot_lines))\n",
    "#random.shuffle(pairs)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "for line in pairs:\n",
    "    input_doc, target_doc = line[0], line[1]\n",
    "    # Appending each input sentence to input_docs\n",
    "    input_docs.append(input_doc)\n",
    "    # Splitting words from punctuation  \n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    # Redefine target_doc below and append it to target_docs\n",
    "    target_doc = '<START> ' + target_doc + ' <END>'\n",
    "    target_docs.append(target_doc)\n",
    "  \n",
    "    # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    for token in target_doc.split():\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "            \n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "num_tokens = len(set(input_tokens + target_tokens)) + 2 # [UNK]\n",
    "pairs = list(zip(input_docs, target_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace out-of-vocabulary words with \"<unk>\" token\n",
    "input_tokenizer = Tokenizer(filters='', oov_token=\"<unk>\")\n",
    "target_tokenizer = Tokenizer(filters='', oov_token=\"<unk>\")\n",
    "\n",
    "# create internal vocabulary\n",
    "input_tokenizer.fit_on_texts(input_docs)\n",
    "target_tokenizer.fit_on_texts(target_docs)\n",
    "\n",
    "# creates sequences of integers out of the given input texts\n",
    "X = input_tokenizer.texts_to_sequences(input_docs)\n",
    "Y = target_tokenizer.texts_to_sequences(target_docs)\n",
    "\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post')\n",
    "Y = tf.keras.preprocessing.sequence.pad_sequences(Y, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2184, 258)\n",
      "(2184, 149)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = len(X_train)\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(sentence):\n",
    "    return max(len(s) for s in sentence)\n",
    "\n",
    "max_length_input = max_len(X)\n",
    "max_length_output = max_len(Y)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1  \n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, \n",
    "                                                                                            drop_remainder=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointwise FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_ffn(embedding_dims, expanded_dims):\n",
    "    return tf.keras.Sequential([\n",
    "           tf.keras.layers.Dense(expanded_dims, activation='relu'),  \n",
    "           tf.keras.layers.Dense(embedding_dims)  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding tokens are explicitly ignored by masking \n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the decoder we want to mask out all of the future tokens\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(input_data, target):\n",
    "    # Encoder padding mask\n",
    "    encoder_padding_mask = create_padding_mask(input_data)\n",
    "  \n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    decoder_padding_mask = create_padding_mask(input_data)\n",
    "  \n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(target)[1])\n",
    "    decoder_target_padding_mask = create_padding_mask(target)\n",
    "    combined_mask = tf.maximum(decoder_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return encoder_padding_mask, decoder_padding_mask, combined_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_self_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  \n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    \n",
    "    # scaling it by the sqrt of the last dimension of k\n",
    "    scaled_scores = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_scores += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_scores, axis=-1)  \n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "embedding_dims = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embedding_dims, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.depth = embedding_dims // num_heads\n",
    "    \n",
    "        self.wq = tf.keras.layers.Dense(embedding_dims)\n",
    "        self.wk = tf.keras.layers.Dense(embedding_dims)\n",
    "        self.wv = tf.keras.layers.Dense(embedding_dims)\n",
    "    \n",
    "        self.dense = tf.keras.layers.Dense(embedding_dims)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "    \n",
    "        q = self.wq(q)  # (batch_size, seq_len, embedding_dims)\n",
    "        k = self.wk(k)  \n",
    "        v = self.wv(v)  \n",
    "    \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len, depth)\n",
    "        k = self.split_heads(k, batch_size)  \n",
    "        v = self.split_heads(v, batch_size)  \n",
    "    \n",
    "        # self_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        self_attention = calculate_self_attention(q, k, v, mask)\n",
    "    \n",
    "        self_attention = tf.transpose(self_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(self_attention, \n",
    "                                     (batch_size, -1, self.embedding_dims))  # (batch_size, seq_len, embedding_dims)\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_dims, num_heads, expanding_dims, rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(embedding_dims, num_heads)\n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.ffn = pointwise_ffn(embedding_dims, expanding_dims)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "  def call(self, x, training, padding_mask):\n",
    "\n",
    "    attn_output = self.mha(x, x, x, padding_mask)  \n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  \n",
    "    \n",
    "    ffn_output = self.ffn(out1) \n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)   # (batch_size, input_seq_len, embedding_dims)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dims, num_heads, expanded_dims, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(embedding_dims, num_heads)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.mha2 = MultiHeadAttention(embedding_dims, num_heads)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.ffn = pointwise_ffn(embedding_dims, expanded_dims)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6) \n",
    "    \n",
    "    def call(self, x, encoder_output, training, padding_mask, look_ahead_mask):\n",
    "\n",
    "        attn1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2 = self.mha2( encoder_output, encoder_output, out1, padding_mask)  \n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  \n",
    "\n",
    "        ffn_output = self.ffn(out2)  \n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, embedding_dims)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, dimensions):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(dimensions)[np.newaxis, :],\n",
    "                            dimensions)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dims, num_heads, expanded_dims, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dims)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                embedding_dims)\n",
    "    \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        self.encoder_layers = [EncoderLayer(embedding_dims, num_heads, expanded_dims, rate) \n",
    "                              for i in range(num_layers)]\n",
    "  \n",
    "    \n",
    "        \n",
    "    def call(self, x, training, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)  \n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dims, tf.float32)) # Technicality that  is used in the original paper\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, padding_mask)\n",
    "    \n",
    "        return x  # (batch_size, input_seq_len, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dims, num_heads, expanded_dims, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, embedding_dims)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, embedding_dims)\n",
    "    \n",
    "        self.decoder_layers = [DecoderLayer(embedding_dims, num_heads, expanded_dims, rate) \n",
    "                       for i in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, encoder_output, training, \n",
    "             padding_mask, look_ahead_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "    \n",
    "        x = self.embedding(x)  \n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dims, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.decoder_layers[i](x, encoder_output, training,\n",
    "                                       padding_mask, look_ahead_mask)\n",
    "  \n",
    "        return x  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, embedding_dims, num_heads, expanded_dims, input_vocab_size, \n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, embedding_dims, num_heads, expanded_dims, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, embedding_dims, num_heads, expanded_dims, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, input, target, training, encoder_padding_mask, \n",
    "             decoder_padding_mask, look_ahead_mask):\n",
    "\n",
    "        encoder_output = self.encoder(input, training, encoder_padding_mask)  # (batch_size, inp_seq_len, embedding_dims)\n",
    "    \n",
    "    \n",
    "        dec_output = self.decoder(target, encoder_output, training, decoder_padding_mask, look_ahead_mask)\n",
    "        # (batch_size, target_seq_len, embedding_dims)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, target_seq_len, target_vocab_size)\n",
    "    \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "expanded_dims = 512\n",
    "\n",
    "transformer = Transformer(num_layers, embedding_dims, num_heads, expanded_dims,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss = loss * mask\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, embedding_dims, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "    \n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.embedding_dims = tf.cast(self.embedding_dims, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.embedding_dims) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(embedding_dims)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.5272\n",
      "Epoch 1 Loss 0.5017\n",
      "Time taken for 1 epoch: 319.62280106544495 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for (batch, (input, target)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        decoder_input = target[ : , :-1 ] # ignore <end> token\n",
    "        real = target[ : , 1: ]           # ignore <start> token\n",
    "    \n",
    "        enc_padding_mask, dec_padding_mask, combined_mask = create_masks(input, decoder_input)\n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(input=input, target=decoder_input, \n",
    "                                      training=True, \n",
    "                                      encoder_padding_mask=enc_padding_mask, \n",
    "                                      decoder_padding_mask=dec_padding_mask,\n",
    "                                      look_ahead_mask=combined_mask)\n",
    "            batch_loss = loss_function(real, predictions)\n",
    "\n",
    "\n",
    "        gradients = tape.gradient(batch_loss, transformer.trainable_variables)    \n",
    "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "        epoch_loss += batch_loss  \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                   epoch + 1, batch, batch_loss.numpy()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, \n",
    "                                         epoch_loss / steps_per_epoch))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
